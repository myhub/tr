# 让CRNN支持多行文本的识别 CRNN For Text With Multiple Lines

一句话：不再需要进行文本行位置的标注，真正的端到端OCR，大大降低标注和开发人员的工作量。
----
主流的OCR技术都会包含文本行检测+文本行识别两个环节，这套方案缺点包括：
+ 标注和模型开发工作量都很大
+ 文本行识别的精度会受到文本行检测精度的影响，整体误差会累积
+ 由于文本行识别模型一般会将文本行从原图中切割出来后进行识别，因此会丢失一些上下文信息从而影响精度

所以我想如果CRNN能够支持多行文本的识别，那么在一些场景下就不需要做文本行检测了，正好现在Transformer很火，不管啥模型加点Transformer似乎都可以提升精度，基于以上想法我做了一些实验，供大家参考。由于模型结构跟CRNN相比几乎没啥修改（仅仅添加了Transformer Encoder来提升模型对全局上下文的学习能力），损失函数也使用CTCLoss，训练代码跟CRNN也相同，所以还是属于CRNN。为了方便区分，后面简称多行CRNN或Multiline CRNN。

#### 使用说明
+ 目前对训练样本进行了随机-15到15度的旋转，如果文本行的倾斜角度过大，识别效果会变差。对于弯曲文本，每个字符的倾斜角度不一样，倾斜角度过大的字符识别效果会比较差
+ 由于合成样本中字体大小集中在14到72像素之间，对于过小或过大的字符识别效果会比较差

#### 推理测试
<pre>
运行环境：
  Ubuntu18+
安装依赖：
  pip install ort==1.2.1

下载 https://github.com/myhub/models/releases/download/1.0/crnn_plus_v1_3.zip 文件后解压
执行 python test.py 即可
</pre>

#### 改进方向
+ 目前特征提取直接使用ResNet将原图下采样到(H<sub>in</sub>/16, W<sub>in</sub>/16)，再将特征Rearrange("B C H W->B (H W) C")后送入Transformer，而标准CRNN是将原图下采样到(H<sub>in</sub>/32, W<sub>in</sub>/4)。加大下采样的倍数，虽然可以显著降低计算量，但可能会导致小号字符难以学习，训练过程中也发现小号字符难以训练。可以考虑将特征提取ResNet替换成ViT或SWin等常见的ImageEncoder。
+ 多行弯曲文本样本合成难度比较大，需要使用代码模拟各种各样的曲线，目前只实现了半圆和一种贝塞尔曲线，样本的缺乏影响弯曲文本的识别率
+ 换行符暂时不支持，影响实际项目中使用
+ 目前只支持384像素以内的图片，需要1张不低于16G显存的显卡才能训练，如果需要支持更大的图片，对显存要求会大幅提高
+ 需要考虑如何将特征序列输出到成熟的LLM大语言模型实现进一步的文档理解
+ 多行CRNN对样本数量要求比单行CRNN高，加上Transformer模型本身对样本数量要求就高，如果希望针对通用OCR场景，还需要添加大量训练样本
+ 进一步测试多行CRNN是否适用于手写文字、表格、数学公式识别等场景

#### 参考项目
+ https://github.com/OleehyO/TexTeller
+ https://github.com/karpathy/nanoGPT
+ https://github.com/BlinkDL/RWKV-LM

